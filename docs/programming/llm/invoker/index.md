# 特征查询中心
## Situation（背景）
内容安全体系依赖多源特征（用户、笔记、直播、商品等）进行 AI 机审决策；
原有各业务线特征查询逻辑分散、重复建设、稳定性差、性能瓶颈突出；
缺乏统一治理能力，难以支撑高并发（峰值 QPS 200w+）与高可用（99.95%+）要求。
## Task（目标）
构建统一特征查询中心，作为机审系统的“数据中枢”；
实现标准化、高性能、高可用、可扩展的特征查询服务；
支撑多业务线（笔记/用户/直播/商品）的实时特征获取需求。
## Action（关键举措）
| 维度    | 技术方案                                                              |
|-------|-------------------------------------------------------------------|
| 架构设计  | 基于泛型 + 反射 + 模板方法，实现`AbstractQueryInvoker Req, Resp `通用引擎，新业务接入零侵入 |
| 性能优化  | 多级缓存（Service 级 + 模型级）+ 内存缓存 + 异步 MQ + 多图并行调用）                     |
| 稳定性保障 | 三级限流（Service / Client / Model） + Sentinel 熔断 + 多级模型降级策略           |
| 可观测性  | 全链路打点 + 缓存命中率监控（图片高笔记不高） + 限流/熔断告警                                |
| 泛化接入  | 通过中间代理转发                                                          |
| 异步重试  | 异步调用场景可传入重试次数，触发缓存建议，失败数据落库定时告警，送人审判断                             |

## Result（成果）
✅ 支撑 QPS 200万+，服务可用性99.95%+；400个节点8核20G

✅ 新业务接入效率提升80%+（仅需继承抽象类 或 泛化接入）；

✅ 模型调用成本降低（通过缓存复用、降级控制）；

✅ 配置驱动：所有缓存 TTL、限流阈值、降级开关均通过 Apollo 动态配置，无需发版；

## Q1：你提到“泛型 + 反射”实现通用查询引擎，具体怎么做的？解决了什么问题？
答： 我们定义了抽象基类 AbstractQueryInvoker Request, Response ，通过模板方法固化查询流程（参数校验 → 业务处理 → 结果返回）。各业务只需继承该类并指定具体的 Request/Response 类型。
启动时，通过反射扫描所有子类，利用 ParameterizedType 获取泛型实际类型，并缓存到 Map String, Metadata  中（key 为 serviceName）。
运行时根据 serviceName 查找元数据，动态创建 Request 对象并调用对应 Invoker。

解决的问题：
避免重复编写查询框架代码；
实现业务逻辑与框架解耦；
新业务接入无需修改核心引擎，符合开闭原则。

## Q2：为什么选择泛型？运行时如何获取泛型的实际类型？
答： 泛型主要带来 类型安全 和 消除强制转换：
编译期即可发现类型错误，避免运行时ClassCastException；
代码更简洁，无需(UserRequest) obj这类强转。
运行时通过以下方式获取泛型类型：

Type genericSuper = getClass().getGenericSuperclass();
我们在启动阶段完成这一解析并缓存，避免每次请求都反射，保证性能。


## Q3：为什么要设计多级缓存？Service 缓存和模型缓存的区别是什么？
答： 因为 缓存粒度和复用场景不同：
Service 缓存：以serviceName + MD5(入参)为 key，适用于整个查询服务的结果缓存。例如note.risk.check服务对某篇笔记的完整风险评分。
模型缓存：以resourceQuery + serviceType + MD5(requestData)为 key，聚焦在底层 AI 模型调用层。例如多个上层服务（笔记审核、评论审核）可能调用同一个图像识别模型，且输入图片相同 → 可复用模型结果。
特别地，在 CommonMutilQueryModelByResourceService 中，一个请求会被拆成多个子请求（如多张图分别调模型），此时 上层无法命中缓存，但子请求可命中模型缓存，显著减少重复计算。

## Q4 模型准入、模型分级
配置中心控制，重保模型，模型准入


## Q5：你们的分布式限流为什么用滑动窗口而不是令牌桶？
答： 主要基于三点考虑：
精确流量控制：滑动窗口能严格限制任意时间窗口内的请求数，而令牌桶在边界处允许突发流量（不符合安全审核的强控需求）；
动态权重公平分配：我们支持按实例负载动态调整配额权重。令牌桶在分布式环境下难以公平迁移未使用配额（如 A 实例空闲，B 实例过载，无法把 A 的配额借给 B）；
实现复杂度：令牌桶在动态调整配额时需处理令牌状态同步，易引发限流失效或抖动；滑动窗口只需维护时间窗口计数，更稳定。
此外，我们还实现了 灰度启动（前60秒只统计不限流） 和 默认权重保护，进一步提升鲁棒性。

## Q6：Sentinel 熔断是如何配置的？熔断后如何降级？
答： 我们对每个下游模型服务配置了 Sentinel 熔断规则：
策略：慢调用比例（如响应时间 > 1s 且比例 > 50%）或异常比例（> 50%）；
熔断时长：30 秒；
最小请求数：100（避免低流量误熔断）。
熔断后降级策略：
返回预设的安全兜底值（如 risk_score=0 表示低风险）；
或直接跳过该模型，进入下一决策环节；
同时触发告警，通知 SRE 介入。

## Q7：多级模型降级在什么场景下会触发？如何实现？
答： 降级主要在以下场景触发：
系统过载：CPU > 80%、线程池耗尽、请求堆积；
模型异常：服务宕机、熔断、异常率飙升；
流量洪峰：热点事件导致 QPS 暴增 10 倍+；
成本控制：模型调用量超预算。

实现方式：
通过 Apollo 动态开关控制是否开启降级；
按模型优先级分级（P0 核心模型保留，P1/P2 非核心模型跳过）；
降级后返回默认值或空结果，不影响主链路。

## Q8：异步 MQ 和线程池是如何优化性能的？
答：
异步因子：某些特征（如用户行为序列）无法实时获取，我们将其放入 RocketMQ 异步计算，结果写入缓存，后续请求可命中；
线程池优化：在CommonMutilQueryModelByResourceService中，对多资源（如多张图）并行调用模型，使用自定义线程池（核心线程数=CPU*2，队列容量可控），避免阻塞主线程；
异步写缓存：查询结果通过单独线程异步写入 Redis，减少主流程 RT。