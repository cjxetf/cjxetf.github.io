# Redis 总结

## 基础数据类型和数据结构
1.字符串：redis没有直接使用C语言传统的字符串表示，而是自己实现的叫做简单动态字符串SDS的抽象类型。C语言的字符串不记录自身的长度信息，而SDS则保存了长度信息，这样将获取字符串长度的时间由O(N)降低到了O(1)，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。

2.链表linkedlist：redis链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向NULL。

3.字典hashtable：用于保存键值对的抽象数据结构。redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的，而是渐进式的。

4.跳跃表skiplist：跳跃表是有序集合的底层实现之一，redis中在实现有序集合键和集群节点的内部结构中都是用到了跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。
**为什么不用红黑树？**
跳表更容易实现并发  （Redis 单线程虽不需并发，但代码简洁是关键）、范围查询高效（O(log N)）其实差不多
额外：ZSet 的跳表 同时维护一个哈希表，用于 O(1) 判断元素是否存在（如 ZSCORE）。

5.整数集合intset：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。

6.压缩列表ziplist：压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。

| 逻辑类型 | 底层编码（encoding）| 底层数据结构说明 |
|----------|---------------------------|------------------|
| String   | int / embstr / raw        | - int：小整数直接存为 long<br>- embstr：短字符串（≤44字节）用连续内存优化<br>- raw：长字符串用 SDS（Simple Dynamic String） |
| Hash     | ziplist → hashtable       | - 小 Hash（元素少、值短）用 压缩列表（ziplist）<br>- 超过阈值后转为 哈希表（dict） |
| List     | ziplist → quicklist（Redis 3.2+） | - 旧版用 ziplist 或 linkedlist<br>- 新版统一为 quicklist（本质是 ziplist 的双向链表） |
| Set      | intset → hashtable        | - 全为整数且数量少 → 整数集合（intset）<br>- 否则 → 哈希表 |
| ZSet     | ziplist → skiplist（跳表） | - 小 ZSet 用 ziplist<br>- 大 ZSet 用 跳表 + 哈希表（跳表用于排序，哈希表用于 O(1) 查找） |

## 版本升级特性
| 版本       | 发布时间 | 核心方向                                             |
|------------|----------|------------------------------------------------------|
| Redis 6.0  | 2020     | 多线程 I/O、ACL、TLS                                 |
| Redis 7.0  | 2022     | Function API（可持久化 + 可命名 + 可管理 + 安全的 Lua 脚本升级版）、Sharded Pub/Sub、多 AOF                |
| Redis 8.0  | 2024     | AI 原生支持（JSON、向量、概率结构）、重归开源、查询引擎 |

## 渐进式reHash
Redis 的 key 本身存在一个大哈希表里，这个表的扩容/缩容就是 rehash —— 它是 Redis 最基础、最高频的 rehash 场景，与你是否使用 Hash 类型无关。大Set类型也是因为需要单元素查询O(1)

| **类别**         | **关键点** |
|------------------|-----------|
| **目的**         | 扩容（负载过高）或缩容（负载过低），维持哈希表性能 |
| **底层结构**     | 字典（dict）包含两个哈希表：`ht[0]`（主表）、`ht[1]`（新表） |
| **触发条件**     | - **扩容**：<br>  • 无 RDB/AOF 时 `load_factor ≥ 1`<br>  • 有 RDB/AOF 时 `load_factor ≥ 5`<br>- **缩容**：`load_factor < 0.1` |
| **rehash 类型**  | **渐进式 rehash**（非一次性，避免阻塞） |
| **核心步骤**     | 1. 创建新表 `ht[1]`<br>2. 设置 `rehashidx = 0`<br>3. 每次操作迁移一个 bucket<br>4. 迁移完成：释放 `ht[0]`，`ht[1] → ht[0]`，`rehashidx = -1` |
| **数据一致性**   | - **查找**：先查 `ht[0]`，再查 `ht[1]`<br>- **新增**：直接写入 `ht[1]` |
| **性能保障**     | - 操作中顺带迁移（分摊成本）<br>- 定时任务（`serverCron`）辅助迁移 |
| **是否阻塞**     | 否，主线程不会因 rehash 长时间阻塞 |
| **是否会丢数据** | 不会，所有操作覆盖两个表，保证完整性 |

## 大 Key 问题
- 尝试将对象分拆成几个K.V， 使用multiGet获取值
  拆成hash存储 hget hmget
  二级缓存、长文本使用mongoDb

- 查找：redis-cli -bigkeys
  删除：scan迭代删，unlink异步删
- 接入监控告警，避免 HGETALL / SMEMBERS / ZRANGE key 0 -1 获取全量数据，改用分页（HSCAN, ZSCAN）
## 热 Key 问题
- 主从读写分离
- 把热key打散再批量获取求和适合计数类
- 加入二级缓存，提前加载热key数据到内存中，监控计算热点触发构建本地缓存

## 缓存击穿、缓存穿透、缓存雪崩
缓存击穿：单key过期高并发打到db
1. 加锁更新，同步锁就行不用分布式锁
2. 异常不断刷新过期时间

缓存雪崩：大量key同时过期
1. 过期时间随机
2. 二级缓存
3. redis高可用，限流

缓存穿透：查DB不存在的数据
1. 前置参数校验
2. 缓存空值，较短ttl
3. redis8.0布隆过滤器（增量数据异步更新）


## 过期策略
- 惰性删除访问时检测删除
- 定期删除会每次随机取一些key去做检查和删除

## 内存淘汰策略

1.volatile-lru：从已设置过期时间的key中，移除最近最少使用的key进行淘汰

2.volatile-ttl：从已设置过期时间的key中，移除将要过期的key

3.volatile-random：从已设置过期时间的key中随机选择key淘汰

4.allkeys-lru：从key中选择最近最少使用的进行淘汰

5.allkeys-random：从key中随机选择key进行淘汰

6.noeviction：当内存达到阈值的时候，新写入操作报错

## 持久化方式
RDB
快照压缩的二进制文件
自动触发（通过配置 save 规则）：save 900 1      # 900 秒内至少 1 次修改 → 触发
手动触发：BGSAVE则是会fork出一个子进程，然后由子进程去负责生成RDB文件


AOF
AOF通过追加、写入、同步三个步骤来实现持久化机制。
1.当AOF持久化处于激活状态，服务器执行完写命令之后，写命令将会被追加append到aof_buf缓冲区的末尾
2.在服务器每结束一个事件循环之前，将会调用flushAppendOnlyFile函数决定是否要将aof_buf的内容保存到AOF文件中，可以通过配置appendfsync来决定。

> always ##aof_buf内容写入并同步到AOF文件
everysec ##默认，将aof_buf中内容每秒写入到AOF文件
no ##将aof_buf内容写入AOF文件，但是并不对AOF文件进行同步，同步时间由操作系统决定

AOF 重写（Rewrite）：
随着时间推移，AOF 文件会膨胀（如 INCR counter 执行 1000 次）
BGREWRITEAOF 命令可压缩日志：用最少命令重建当前状态


## Redis集群原理
1. 数据分片：Hash Slot（哈希槽）机制
   Redis Cluster 将整个 key 空间划分为 16384 个哈希槽（hash slots）
   slot = CRC16(key) % 16384
2. 节点角色：主从架构
      Master（主节点）	N ≥ 3	负责写入 + 读取 + 管理部分 hash slot
      Replica（从节点）	≥1 per master	异步复制主节点数据，用于故障转移
      ⚠️ 最小集群要求：3 主 + 3 从（共 6 节点），才能容忍 1 个主节点故障。
3. Gossip 协议：去中心化通信
   节点间通过 Gossip 协议交换集群状态，无需中心协调：
   A收到B的MEET进行互相握手，再通过gossip协议把节点B的信息传播给集群中的其他节点，其他节点也将和B进行握手
   MEET：新节点加入集群
   PING/PONG：心跳检测 + 传播元数据（槽分配、故障信息等）
   FAIL：广播某个主节点已下线
   所有节点维护一份 集群拓扑视图（cluster nodes），包含：节点 ID、IP:Port、角色（master/slave）、负责的槽范围、故障状态

4. 客户端重定向（Redirection）
   客户端首次连接任意节点
   若 key 不在当前节点，返回 MOVED 重定向：
   MOVED 1234 192.168.1.10:7001
   Smart Client（如 Lettuce、Jedis Cluster）会缓存槽路由表，后续直接访问正确节点
   💡 避免频繁重定向：客户端需支持 CLUSTER SLOTS 命令获取完整路由。
5. 故障检测与自动转移
   主观下线（PFail）：某节点认为主节点不可达
   客观下线（Fail）：半数以上主节点 agree → 标记为 fail
   从节点发起选举：复制偏移量最大的从节点胜出
   晋升为主：广播 PONG 更新集群状态
   整个过程通常 10~30 秒（可调 cluster-node-timeout）

## Redis 事务机制
redis通过MULTI、EXEC、WATCH等命令来实现事务机制，事务执行过程将一系列多个命令按照顺序一次性执行，并且在执行期间，事务不会被中断，也不会去执行客户端的其他请求，直到所有命令执行完毕。事务的执行过程如下：

1.服务端收到客户端请求，事务以MULTI开始

2.如果客户端正处于事务状态，则会把事务放入队列同时返回给客户端QUEUED，反之则直接执行这个命令

3.当收到客户端EXEC命令时，WATCH命令监视整个事务中的key是否有被修改，如果有则返回空回复到客户端表示失败，否则redis会遍历整个事务队列，执行队列中保存的所有命令，最后返回结果给客户端

WATCH的机制本身是一个CAS的机制，被监视的key会被保存到一个链表中，如果某个key被修改，那么REDIS_DIRTY_CAS标志将会被打开，这时服务器会拒绝执行事务。