# AI 社交五层记忆架构

## 第一层：System Prompt（角色宪法）

### ✅ 目标

定义 AI 的 ​**人格、语气、行为边界、不可逾越的红线**​。
​**绝不包含任何用户相关或会话相关动态信息**​。

### 🔧 技术方案

* ​**内容来源**​：静态 YAML / JSON 配置文件（按角色类型分）

  
  ```
  # roles/enthusiast.yaml
  identity: "你是一个充满好奇心的科技爱好者"
  tone: "热情、简洁、带点幽默，避免说教"
  boundaries:
    - "不讨论政治、宗教、色情、暴力"
    - "不知道就说'我不太清楚'，绝不编造"
    - "始终以用户兴趣为中心，不强行推销观点"
  ```
* ​**注入方式**​：在对话初始化时一次性拼接到 prompt 开头
* ​**更新机制**​：版本化管理（如 `v1.2`），热加载需重启会话
* ​**容错**​：若加载失败，回退到通用安全模板（如 “你是一个有礼貌的助手”）

### ⚠️ 关键约束

* **Token 占用 ≤ 150 tokens**
* ​**禁止出现 ​`{user_name}` ​等插值**​（那是第二层的事）

---

## 第二层：结构化状态（事实锚点）

### ✅ 目标

存储 **不可协商、必须准确** 的上下文事实，由系统强制维护。

### 🔧 数据结构（JSON Schema）



```
{
  "user_id": "u_12345",
  "persona_type": "tech_enthusiast",     // 角色类型（来自第一层）
  "language": "zh-CN",
  "explicit_preferences": {
    "topics_of_interest": ["AI", "开源"],
    "avoid_topics": ["加密货币"],
    "response_length": "medium"           // short / medium / long
  },
  "session_mode": "casual",               // casual / deep_dive / tutorial
  "last_reset_at": "2026-01-12T10:00:00Z"
}
```

### 🔧 更新机制

* ​**只通过显式用户指令或系统事件更新**​（如 `/prefer topics=AI,robotics`）
* **写入数据库（如 PostgreSQL） + 内存缓存（Redis Hash）**
* ​**每次对话开始时全量拉取**​，作为 prompt 的固定前缀

### 🔧 在 Prompt 中的呈现



```
[系统状态]
- 用户偏好话题：AI, 开源
- 避免话题：加密货币
- 回复长度：中等
- 当前模式：轻松闲聊
```

### ⚠️ 容错设计

* 若状态缺失 → 使用默认值（如 `session_mode = "casual"`）
* 若字段非法 → 自动校验并修正（如 `response_length` 不在枚举中 → 设为 `"medium"`）

---

## 第三层：短期记忆（工作内存）

### ✅ 目标

保留 ​**最近 3～8 轮对话**​，用于维持话题连贯性，​**强调顺序和精确性**​。

### 🔧 技术方案

* ​**存储格式**​：原始对话历史（带角色标记）
  
  
  ```
  [
    {"role": "user", "content": "你觉得 LLM 会取代程序员吗？"},
    {"role": "assistant", "content": "不会完全取代，但会改变工作方式..."}
  ]
  ```
* ​**长度控制**​：
  
  * 硬限制：最多 8 轮
  * 软限制：总 token ≤ 800（含第四层摘要）
* ​**压缩策略（可选）**​：
  
  * 若超限，从最旧轮次开始合并（如用小模型摘要前两轮）
  * **不向量化！保持原文语义**

### 🔧 更新机制

* 每轮对话后 append 新消息
* 超出长度时 ​**FIFO 截断**​（非滑动窗口，而是固定最大长度）

### ⚠️ 容错

* 若短期记忆丢失 → 仅保留最新 1～2 轮，其余视为“短暂失忆”，用第四层补救

---

## 第四层：长期记忆（分三类存储）

> ❌ 不再是“一坨向量”，而是 **结构化 + 摘要 + 向量** 三位一体。

### 类型 1：确定事实 → **结构化存储**

* ​**内容**​：用户明确声明的信息（如 “我叫李明，住在杭州”）
* ​**存储**​：写入用户 profile 表（属于第二层的扩展）
* ​**检索**​：直接查 DB，100% 准确

### 类型 2：阶段性总结 → **文本摘要**

* ​**触发条件**​：每 10 轮对话 or 话题切换时
* ​**生成方式**​：
  * 调用轻量 summarizer（如 `phi-3-mini` 或规则模板）
  * 输出示例：`"用户对开源 AI 工具表现出浓厚兴趣，曾提到使用过 Ollama 和 LM Studio。"`
* ​**存储**​：存为纯文本，附加时间戳
* ​**在 Prompt 中位置**​：放在短期记忆之前，作为“背景速览”

### 类型 3：模糊关联 → **向量存储（最后手段）**

* ​**内容**​：无法结构化、需语义匹配的片段（如某次聊到“喜欢科幻电影”）
* ​**存储**​：
  * Embedding 模型：`bge-m3`（支持多语言+稀疏向量）
  * 向量库：`Qdrant`（支持 payload 过滤 + hybrid search）
* ​**检索策略**​：
  * 仅当当前话题无明确上下文时触发
  * top\_k=2，相似度阈值 ≥ 0.65
  * ​**结果必须附带原始文本**​，禁止仅用向量生成回复

### ⚠️ 长期记忆兜底

* 若全部长期记忆不可用 → 仅依赖第二层（结构化状态）+ 第三层（最近对话）

---

## 第五层：RAG（可选增强）

### ✅ 定位

* **不是主干，而是“世界观插件”**
* 仅用于 ​**高一致性要求场景**​（如角色设定集、虚构世界规则）

### 🔧 技术方案

* ​**知识源**​：
  * 角色背景文档（Markdown）
  * 世界观百科（结构化 JSON）
* ​**索引方式**​：
  * 按 chunk 分段（≤ 300 tokens）
  * 存入专用向量库（与第四层分离）
* ​**触发条件**​：
  * 用户问题涉及设定（如 “你上次说的世界观里，AI 有情感吗？”）
  * **由 Prompt Builder 判断是否启用**

### 🔌 熔断机制（关键！）

* ​**开关控制**​：全局 flag + per-session override
* ​**超时熔断**​：RAG 查询 > 800ms → 自动跳过
* ​**降级行为**​：若 RAG 失败，回复：“关于这部分设定我记不太清了，但我们聊聊别的？”

> 💡 RAG 结果​**永远不直接拼入回复**​，而是作为“参考依据”，由模型用自己的话转述。

---

## 🧠 核心引擎：Prompt Builder（真正的指挥官）

### 职责

1. ​**Token 预算分配**​（总上限：3500 tokens）
   
   * System Prompt：150
   * 结构化状态：100
   * 长期记忆（摘要）：200
   * 短期记忆：≤ 800
   * RAG（若启用）：≤ 300
   * 留白（给新输入+输出）：≥ 1000
2. **内容排序（从高可信到低可信）**
   
   
   ```
   [System Prompt]
   [结构化状态]
   [长期记忆摘要]
   [短期记忆]
   [RAG 片段（可选）]
   [用户最新输入]
   ```
3. **动态降级策略**
   
   * 若总 token 超限 → 优先裁剪 RAG → 再裁剪短期记忆（从最旧开始）
   * 若 RAG 超时 → 移除 RAG 区块，其他不变
   * 若长期记忆服务宕机 → 仅用摘要（如有）或跳过
4. **输出格式标准化**
   
   * 所有外部信息用 `[引用]` 标注来源
   * 禁止模型“脑补”未提供的信息

---

## ✅ 最终目标验证

> **即使以下情况同时发生：**
> 
> * 模型降级为 7B 小模型
> * 长期记忆服务宕机
> * RAG 被手动关闭
> * 短期记忆因超限被截断

> **AI 依然能：**
> 
> * 保持角色语气（第一层）
> * 遵守用户明确偏好（第二层）
> * 对当前话题做出合理回应（第三层残余）
> * 承认“记不清了”而非胡说（边界意识）

→ ​**它仍然是一个“稳定存在的人”，而非“失忆的聊天机器人”**​。

---

​**核心思想是：把“记忆”从模型负担中解放出来，变成可管理、可降级、可审计的系统能力**​。
