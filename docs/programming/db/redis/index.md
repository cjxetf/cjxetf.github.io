# Redis 总结

## 基础数据类型和数据结构
1.字符串：redis没有直接使用C语言传统的字符串表示，而是自己实现的叫做简单动态字符串SDS的抽象类型。C语言的字符串不记录自身的长度信息，而SDS则保存了长度信息，这样将获取字符串长度的时间由O(N)降低到了O(1)，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。

2.链表linkedlist：redis链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向NULL。

3.字典hashtable：用于保存键值对的抽象数据结构。redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的，而是渐进式的。

4.跳跃表skiplist：跳跃表是有序集合的底层实现之一，redis中在实现有序集合键和集群节点的内部结构中都是用到了跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。
**为什么不用红黑树？**
跳表更容易实现并发  （Redis 单线程虽不需并发，但代码简洁是关键）、范围查询高效（O(log N)）其实差不多
额外：ZSet 的跳表 同时维护一个哈希表，用于 O(1) 判断元素是否存在（如 ZSCORE）。

5.整数集合intset：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。

6.压缩列表ziplist：压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。

| 逻辑类型 | 底层编码（encoding）| 底层数据结构说明 |
|----------|---------------------------|------------------|
| String   | int / embstr / raw        | - int：小整数直接存为 long<br>- embstr：短字符串（≤44字节）用连续内存优化<br>- raw：长字符串用 SDS（Simple Dynamic String） |
| Hash     | ziplist → hashtable       | - 小 Hash（元素少、值短）用 压缩列表（ziplist）<br>- 超过阈值后转为 哈希表（dict） |
| List     | ziplist → quicklist（Redis 3.2+） | - 旧版用 ziplist 或 linkedlist<br>- 新版统一为 quicklist（本质是 ziplist 的双向链表） |
| Set      | intset → hashtable        | - 全为整数且数量少 → 整数集合（intset）<br>- 否则 → 哈希表 |
| ZSet     | ziplist → skiplist（跳表） | - 小 ZSet 用 ziplist<br>- 大 ZSet 用 跳表 + 哈希表（跳表用于排序，哈希表用于 O(1) 查找） |

## 版本升级特性
| 版本       | 发布时间 | 核心方向                                             |
|------------|----------|------------------------------------------------------|
| Redis 6.0  | 2020     | 多线程 I/O、ACL、TLS                                 |
| Redis 7.0  | 2022     | Function API（可持久化 + 可命名 + 可管理 + 安全的 Lua 脚本升级版）、Sharded Pub/Sub、多 AOF                |
| Redis 8.0  | 2024     | AI 原生支持（JSON、向量、概率结构）、重归开源、查询引擎 |

## 渐进式reHash
Redis 的 key 本身存在一个大哈希表里，这个表的扩容/缩容就是 rehash —— 它是 Redis 最基础、最高频的 rehash 场景，与你是否使用 Hash 类型无关。大Set类型也是因为需要单元素查询O(1)

| **类别**         | **关键点** |
|------------------|-----------|
| **目的**         | 扩容（负载过高）或缩容（负载过低），维持哈希表性能 |
| **底层结构**     | 字典（dict）包含两个哈希表：`ht[0]`（主表）、`ht[1]`（新表） |
| **触发条件**     | - **扩容**：<br>  • 无 RDB/AOF 时 `load_factor ≥ 1`<br>  • 有 RDB/AOF 时 `load_factor ≥ 5`<br>- **缩容**：`load_factor < 0.1` |
| **rehash 类型**  | **渐进式 rehash**（非一次性，避免阻塞） |
| **核心步骤**     | 1. 创建新表 `ht[1]`<br>2. 设置 `rehashidx = 0`<br>3. 每次操作迁移一个 bucket<br>4. 迁移完成：释放 `ht[0]`，`ht[1] → ht[0]`，`rehashidx = -1` |
| **数据一致性**   | - **查找**：先查 `ht[0]`，再查 `ht[1]`<br>- **新增**：直接写入 `ht[1]` |
| **性能保障**     | - 操作中顺带迁移（分摊成本）<br>- 定时任务（`serverCron`）辅助迁移 |
| **是否阻塞**     | 否，主线程不会因 rehash 长时间阻塞 |
| **是否会丢数据** | 不会，所有操作覆盖两个表，保证完整性 |

## 大 Key 问题
- 尝试将对象分拆成几个K.V， 使用multiGet获取值
  拆成hash存储 hget hmget
  二级缓存、长文本使用mongoDb

- 查找：redis-cli -bigkeys
  删除：scan迭代删，unlink异步删
- 接入监控告警，避免 HGETALL / SMEMBERS / ZRANGE key 0 -1 获取全量数据，改用分页（HSCAN, ZSCAN）
## 热 Key 问题
- 主从读写分离
- 把热key打散再批量获取求和适合计数类
- 加入二级缓存，提前加载热key数据到内存中，监控计算热点触发构建本地缓存

## 缓存击穿、缓存穿透、缓存雪崩
缓存击穿：单key过期高并发打到db
1. 加锁更新，同步锁就行不用分布式锁
2. 异常不断刷新过期时间

缓存雪崩：大量key同时过期
1. 过期时间随机
2. 二级缓存
3. redis高可用，限流

缓存穿透：查DB不存在的数据
1. 前置参数校验
2. 缓存空值，较短ttl
3. redis8.0布隆过滤器（增量数据异步更新）


## 过期策略
- 惰性删除访问时检测删除
- 定期删除会每次随机取一些key去做检查和删除

## 内存淘汰策略

1.volatile-lru：从已设置过期时间的key中，移除最近最少使用的key进行淘汰

2.volatile-ttl：从已设置过期时间的key中，移除将要过期的key

3.volatile-random：从已设置过期时间的key中随机选择key淘汰

4.allkeys-lru：从key中选择最近最少使用的进行淘汰

5.allkeys-random：从key中随机选择key进行淘汰

6.noeviction：当内存达到阈值的时候，新写入操作报错

## 持久化方式
RDB
快照压缩的二进制文件
自动触发（通过配置 save 规则）：save 900 1      # 900 秒内至少 1 次修改 → 触发
手动触发：BGSAVE则是会fork出一个子进程，然后由子进程去负责生成RDB文件


AOF
AOF通过追加、写入、同步三个步骤来实现持久化机制。
1.当AOF持久化处于激活状态，服务器执行完写命令之后，写命令将会被追加append到aof_buf缓冲区的末尾
2.在服务器每结束一个事件循环之前，将会调用flushAppendOnlyFile函数决定是否要将aof_buf的内容保存到AOF文件中，可以通过配置appendfsync来决定。

> always ##aof_buf内容写入并同步到AOF文件
everysec ##默认，将aof_buf中内容每秒写入到AOF文件
no ##将aof_buf内容写入AOF文件，但是并不对AOF文件进行同步，同步时间由操作系统决定

AOF 重写（Rewrite）：
随着时间推移，AOF 文件会膨胀（如 INCR counter 执行 1000 次）
BGREWRITEAOF 命令可压缩日志：用最少命令重建当前状态


## Redis集群原理
1. 数据分片：Hash Slot（哈希槽）机制
   Redis Cluster 将整个 key 空间划分为 16384 个哈希槽（hash slots）
   slot = CRC16(key) % 16384
2. 节点角色：主从架构
      Master（主节点）	N ≥ 3	负责写入 + 读取 + 管理部分 hash slot
      Replica（从节点）	≥1 per master	异步复制主节点数据，用于故障转移
      ⚠️ 最小集群要求：3 主 + 3 从（共 6 节点），才能容忍 1 个主节点故障。
3. Gossip 协议：去中心化通信
   节点间通过 Gossip 协议交换集群状态，无需中心协调：
   A收到B的MEET进行互相握手，再通过gossip协议把节点B的信息传播给集群中的其他节点，其他节点也将和B进行握手
   MEET：新节点加入集群
   PING/PONG：心跳检测 + 传播元数据（槽分配、故障信息等）
   FAIL：广播某个主节点已下线
   所有节点维护一份 集群拓扑视图（cluster nodes），包含：节点 ID、IP:Port、角色（master/slave）、负责的槽范围、故障状态

4. 客户端重定向（Redirection）
   客户端首次连接任意节点
   若 key 不在当前节点，返回 MOVED 重定向：
   MOVED 1234 192.168.1.10:7001
   Smart Client（如 Lettuce、Jedis Cluster）会缓存槽路由表，后续直接访问正确节点
   💡 避免频繁重定向：客户端需支持 CLUSTER SLOTS 命令获取完整路由。
5. 故障检测与自动转移
   主观下线（PFail）：某节点认为主节点不可达
   客观下线（Fail）：半数以上主节点 agree → 标记为 fail
   从节点发起选举：复制偏移量最大的从节点胜出
   晋升为主：广播 PONG 更新集群状态
   整个过程通常 10~30 秒（可调 cluster-node-timeout）

## Redis 事务机制
redis通过MULTI、EXEC、WATCH等命令来实现事务机制，事务执行过程将一系列多个命令按照顺序一次性执行，并且在执行期间，事务不会被中断，也不会去执行客户端的其他请求，直到所有命令执行完毕。事务的执行过程如下：

1.服务端收到客户端请求，事务以MULTI开始

2.如果客户端正处于事务状态，则会把事务放入队列同时返回给客户端QUEUED，反之则直接执行这个命令

3.当收到客户端EXEC命令时，WATCH命令监视整个事务中的key是否有被修改，如果有则返回空回复到客户端表示失败，否则redis会遍历整个事务队列，执行队列中保存的所有命令，最后返回结果给客户端

WATCH的机制本身是一个CAS的机制，被监视的key会被保存到一个链表中，如果某个key被修改，那么REDIS_DIRTY_CAS标志将会被打开，这时服务器会拒绝执行事务。


## 主从同步原理
1. 核心流程（3 阶段）
- 阶段 1：全量复制（首次同步 / 从库离线后重连）
   从库发送 slaveof 命令，向主库发起同步请求。
   主库执行 bgsave 生成 RDB 快照，同时将快照生成期间的写命令缓存到「复制缓冲区」。
   主库发送 RDB 文件给从库，从库接收后清空本地数据，加载 RDB 恢复初始状态。
   主库发送缓存的写命令，从库执行命令，最终与主库数据一致。
- 阶段 2：增量复制（日常同步）
   全量同步完成后，主库每执行一条写命令（set、hmset 等），都会实时发送给从库。
   从库接收命令后异步执行，保持与主库的增量同步。
   依赖「复制偏移量」和「运行 ID」：主从库各自维护偏移量（记录已同步的命令位置），运行 ID 用于识别主库（主库重启后运行 ID 变更，从库会触发全量复制）。
- 阶段 3：断连重连（网络抖动后）
   从库断连后，会缓存本地未同步的命令偏移量。
   重连后，从库向主库发送「偏移量 + 运行 ID」，主库判断偏移量是否在自身「复制积压缓冲区」（默认 1MB，可配置）内：
   若在：主库发送偏移量后的增量命令，触发增量复制（高效）。
   若不在：触发全量复制（兜底）。
2. 面试亮点（差异化回答）
- 异步复制的权衡：Redis 主从是「异步复制」（主库发送命令后无需等待从库确认），优势是不阻塞主库写操作，性能高；缺点是极端情况下（主库宕机）可能丢失少量数据 —— 解决方案：开启 min-replicas-to-write（要求至少 N 个从库同步完成才允许主库写），平衡性能与一致性。
- 复制积压缓冲区的作用：本质是环形缓冲区，主库持续写入最新命令，用于断连后快速判断是否需要全量复制，减少全量复制的频率（全量复制耗带宽和 CPU）。
- 无中心化设计：支持「一主多从」「从库再挂从库」（树状结构），从库可分担读压力（读写分离），主库仅负责写，提升整体吞吐量。
- 常见优化点：主库禁用 RDB 压缩（节省 CPU）、从库开启「只读模式」（防止误写）、增大复制积压缓冲区（减少断连后全量复制概率）。

## 主从延迟
| **类别** | **具体原因** | **表现特征** | **排查命令/工具** |
|----------|--------------|----------------|--------------------|
| **1. 主节点写入压力过大** | - 高频写入（如每秒数万次 SET）<br>- 大 Key 操作（如 Hash 含百万字段、List 超长）<br>- 批量操作未用 Pipeline（如循环单条写）<br>- 执行 `FLUSHDB` / `FLUSHALL` | - `master_repl_offset` 增长极快<br>- 从节点 `slave_repl_offset` 追不上<br>- 主节点 CPU 或网络打满 | `INFO COMMANDSTATS`<br>`redis-cli --bigkeys`<br>`netstat -i` / `iftop` |
| **2. 网络问题** | - 主从跨机房/跨地域部署<br>- 网络带宽不足（如千兆网跑满）<br>- 网络丢包或高延迟（>5ms） | - `INFO REPLICATION` 中偏移量差持续扩大<br>- `ping` 延迟高<br>- `tcpdump` 显示重传 | `ping` / `mtr`<br>`iftop` / `nethogs`<br>`ss -i`（查看 TCP RTT） |
| **3. 从节点性能瓶颈** | - CPU 资源不足（无法及时执行命令）<br>- 内存 swap（物理内存不足）<br>- 磁盘 IO 高（若开启 AOF/RDB） | - 从节点 CPU 使用率 >90%<br>- `si/so`（swap in/out）非零<br>- `iostat` 显示高 IO wait | `top` / `htop`<br>`free -h`<br>`iostat -x 1` |
| **4. 从节点负载过高** | - 承担大量读请求（尤其复杂查询如 `KEYS *`、`SMEMBERS`）<br>- 客户端连接数过多 | - `INFO CLIENTS` 显示大量连接<br>- 慢查询日志有耗时命令 | `INFO CLIENTS`<br>`SLOWLOG GET 10` |
| **5. 复制缓冲区溢出** | - `repl-backlog-size` 设置过小<br>- 从节点短暂断连后需全量同步 | - 日志出现 `Partial resynchronization not accepted: Replication ID mismatch`<br>- 从节点频繁 `FULLRESYNC` | `grep -i "fullresync" /var/log/redis.log`<br>`INFO REPLICATION` |
| **6. 持久化阻塞** | - 主/从执行 `BGSAVE` 或 `AOF rewrite`<br>- fork 耗时长（内存大时） | - `INFO PERSISTENCE` 中 `latest_fork_usec` 很高（>100ms）<br>- 复制暂停几秒 | `INFO PERSISTENCE`<br>`dmesg \| grep -i kill`（检查 OOM） |
| **7. Redis 版本或配置缺陷** | - Redis < 6.0，无 I/O 多线程<br>- 未调优 `client-output-buffer-limit` | - 升级后延迟明显改善<br>- 从节点被主节点强制断开 | `redis-server --version`<br>检查 `redis.conf` |

| **维度** | **最佳实践** | **配置示例 / 操作说明** | **适用场景** | **注意事项** |
|----------|--------------|--------------------------|--------------|---------------|
| **部署架构** | 主从部署在同一可用区（AZ） | 云厂商选择同 AZ 实例 | 所有生产环境 | 跨 AZ 延迟通常 <2ms，跨 Region 可能 >50ms |
| | 从节点资源配置 ≥ 主节点 | CPU 核数、内存、网络带宽不低于主 | 高并发读场景 | 避免“主强从弱” |
| **监控告警** | 部署心跳键监控延迟 | ```bash<br># 主每秒：<br>SETEX redis_heartbeat 10 $(date +%s)<br># 从读取：<br>lag=$(($(date +%s) - $(redis-cli get redis_heartbeat)))<br>``` | 所有集群 | 心跳 key TTL 建议 10~30 秒 |
| | 监控复制偏移量差 | `master_offset - slave_offset > 10MB` 告警 | 大数据量写入 | 结合业务写入速率设定阈值 |
| **参数调优** | 增大复制积压缓冲区 | `repl-backlog-size 512mb`（默认 1MB） | 写入突增、从节点可能短暂断连 | 值 = 平均写入速率 × 最大容忍断连时间 |
| | 调大从节点输出缓冲区 | `client-output-buffer-limit slave 1g 256mb 60` | 大 Key 同步、网络波动 | 防止主节点因“慢从”断开连接 |
| | 启用 I/O 多线程（Redis 6+） | ```ini<br>io-threads 4<br>io-threads-do-reads yes<br>``` | 多核机器、高网络吞吐 | 线程数 ≤ CPU 核数，避免上下文切换开销 |
| **写入优化** | 避免大 Key | 单个 Hash/List/Sorted Set 元素数 < 1万 | 所有写入场景 | 使用 `redis-cli --bigkeys` 定期扫描 |
| | 批量写入用 Pipeline | Java: `pipeline.set(key, val); pipeline.sync();` | 批量导入、缓存预热 | 减少网络往返，提升吞吐 |
| | 关键写操作后加 `WAIT`（谨慎） | `WAIT 1 500`（等1个从，超时500ms） | 强一致性要求高的操作 | 会增加写延迟，降低 QPS |
| **读策略** | 强一致数据读主库 | 用户余额、订单状态、Token 等 | 金融、交易类业务 | 应用层路由逻辑 |
| | 弱一致数据读从库 + 延迟熔断 | 若 `lag > 1s`，自动切回主库 | 缓存、排行榜、日志 | 需实现延迟感知客户端或 Proxy |
| | 多从节点分担读负载 | replica-1：实时读；replica-2：报表分析 | 高读并发场景 | 避免单一从节点过载 |
| **持久化** | 从节点关闭持久化（若仅用于读） | ```ini<br>save ""<br>appendonly no<br>``` | 纯读从节点 | 减少 fork 和磁盘 IO 开销 |
| | 主节点合理配置 RDB/AOF | 避免高峰时段 `BGSAVE` | 所有主节点 | 使用 `bgsave-schedule` 或错峰备份 |
| **版本与维护** | 升级到 Redis 6+ | 利用 I/O 多线程、ACL、更好的复制 | 新项目或可升级环境 | 注意兼容性测试 |
| | 定期清理无用 Key | 避免内存膨胀导致 fork 慢 | 长期运行集群 | 使用 `EXPIRE` 或定期 `SCAN + DEL` |