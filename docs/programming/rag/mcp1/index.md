# MCP Server（Tool 集合）缓存设计方案

在 LLM Agent 架构中，MCP Server 负责执行 LLM 发出的具体操作（如查数据库、调 API、运行代码等）。为提升性能、降低外部依赖压力并控制成本，需对 **Tool 执行结果**进行精细化缓存。

---

## 一、缓存目标

- 避免重复执行相同参数的 Tool
- 减少对外部系统（数据库、第三方 API）的压力
- 降低端到端延迟（尤其对高频或慢速 Tool）
- 控制资源消耗（如沙箱启动、进程开销）

---

## 二、缓存适用性判断

并非所有 Tool 都适合缓存。需满足以下至少一项：

✅ **幂等性**：相同输入始终产生相同输出（如数学计算、只读查询）  
✅ **时效容忍**：结果在一段时间内有效（如天气、汇率、商品价格）

❌ **禁止缓存**：
- 涉及状态变更（如 `send_email()`、`place_order()`）
- 强实时性要求（如 `get_current_gps()`）
- 含敏感上下文（除非 Key 做用户隔离）

> **建议**：在 Tool 注册时显式声明缓存策略：
> ```python
> @tool(cache_ttl=300, cache_key_params=["symbol"])
> def get_stock_price(symbol: str) -> float:
>     ...
> ```

---

## 三、缓存层级设计

### 1. L1：本地内存缓存（单实例热点）
- **适用**：高频、低延迟内部工具（如格式转换、规则引擎）
- **技术**：`functools.lru_cache`（Python）、Caffeine（Java）
- **TTL**：短（1–60 秒），防内存泄漏
- **局限**：多副本部署时命中率有限

### 2. L2：分布式缓存（跨实例共享，核心层）
- **推荐存储**：Redis / Memcached
- **Key 设计原则**：
  - 包含 Tool 名称
  - 包含所有输入参数（排序 + 序列化 + 哈希）
  - 可选：版本号、租户 ID

### 3. L3：语义缓存（可选）
- **场景**：LLM 用不同自然语言触发同一功能（如“北京天气” vs “北京气温多少”）
- **方案**：
- 前置轻量 NLU 模块，将 NL 映射为结构化 Tool 调用
- 对原始 query 做 embedding，构建向量索引 → 映射到已缓存结果
- **注意**：增加复杂度，建议按需启用

---

## 四、缓存 Key 设计最佳实践

- **参数标准化**：dict/list 排序、去空格、类型归一化
- **脱敏处理**：避免敏感信息入 Key（如用 `hash(user_id)` 替代手机号）
- **版本控制**：Tool 逻辑升级时，Key 加版本（如 `v2`），避免旧缓存污染
- **命名空间隔离**：按环境/租户划分，如 `prod:mcp:tool:...`

---

## 五、缓存失效策略

| 触发条件 | 失效方式 |
|--------|--------|
| 时间过期 | Redis 设置 `EXPIRE`（推荐） |
| 数据源变更 | 监听 binlog / 消息队列，主动删除相关 key（如 `user_updated → del mcp:tool:get_user:123`） |
| Tool 代码更新 | 切换 Key 版本前缀（`v1` → `v2`），旧缓存自动淘汰 |
| 手动清除 | 提供运维接口：`/cache/clear?tool=get_weather&params=...` |

> ⚠️ **关键原则**：精准失效，禁止全局 flush，防止缓存雪崩。

---

## 六、特殊 Tool 的缓存策略

| Tool 类型 | 缓存建议 |
|---------|--------|
| **只读数据库查询** | 强缓存，TTL 根据数据更新频率（用户资料 5min，商品目录 1h） |
| **第三方 API 调用** | 必须缓存！TTL 遵循 API 文档（如 GitHub API 60s） |
| **代码解释器（Code Interpreter）** | 仅缓存无副作用的纯函数代码，Key 含完整代码 + 输入 |
| **搜索类（企业知识库）** | 可缓存 `query → results`，但需联动文档更新失效 |
| **写操作 / 有副作用** | **禁止缓存** |

---

## 七、监控与可观测性

必须监控以下指标：
- 各 Tool 的缓存命中率（分 L1/L2）
- 因缓存节省的外部调用次数（如减少 80% 的天气 API 调用）
- 缓存命中 vs 未命中时的 P99 延迟对比
- 缓存存储占用（防大结果撑爆 Redis）
- 缓存穿透/击穿告警（大量 miss 可能预示异常）

---

## 八、部署建议

- Redis 集群独立部署，与 MCP 计算节点分离
- 对超大结果（>1MB）：
- 要么不缓存
- 要么缓存到对象存储（S3），Redis 仅存 URL
- 使用连接池 + pipeline 优化 Redis 访问性能
- 封装统一 `@cached_tool` 装饰器，降低开发成本

---

## 总结

对于作为 **Tool 集合的 MCP Server**，缓存本质是 **“确定性函数结果缓存”**。  
通过 **参数化 Key + 分布式缓存 + 精准失效**，可在保证正确性的前提下，显著提升吞吐、降低延迟与外部依赖成本。

> **终极目标**：让 MCP Server 在高并发下表现得像一个 **高性能、低延迟、高可用的“确定性服务网格”**。
